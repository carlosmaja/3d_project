# -*- coding: utf-8 -*-
"""Copia de Recontruction_IMAGES.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l20YCuNcmqrIa_GGnxl1vFBUeXp9yB6m
"""

# Commented out IPython magic to ensure Python compatibility.

import os
import cv2
import numpy as np
# %pip install patchify
from patchify import patchify, unpatchify
from skimage import io, util
from skimage import img_as_ubyte
from matplotlib import pyplot as plt
from PIL import Image
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler, StandardScaler
#import tifffile as tfl
#import matplotlib.image as mpimg

# %pip install keras_unet_collection
from keras_unet_collection import models, losses
# %pip install tensorflow
from tensorflow.keras.metrics import MeanIoU

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras import backend as K
#%pip install segmentation_models
import segmentation_models as sm
from keras.utils import normalize
def jaccard_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)

weights = [0.1666, 0.1666]
dice_loss = sm.losses.DiceLoss()#(class_weights=weights)
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)
#metrics = ['accuracy', jaccard_coef]
from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/UNet_2D_v4_4epochs_16batchs-Hierrog.hdf5"
#model = load_model("/content/drive/MyDrive/Colab Notebooks/UNet_2D_v2-5epochs_16batchs-Hierrog_Im+Mk-Hierrof_Mk.hdf5"
#model = load_model("/content/drive/MyDrive/Colab Notebooks/UNet_2D_v3_7epochs_16batchs-Hierrog.hdf5"
#model = load_model("/content/drive/MyDrive/Colab Notebooks/UNet_2D_v0-Hierro_gris_nodular_solo_mascaras_UNet_2D_20epochs_16batchs.hdf5"
                   ,custom_objects={'dice_loss_plus_1focal_loss': total_loss,
                                    'jaccard_coef':jaccard_coef}
                   )
print(model.summary())
for layer in model.layers:
  print(layer.name)

from skimage import io, util
# Leer todas las imágenes JPG en un directorio específico
imagenes = []
files=[]
for i in range(1,10):
  file=(f'/content/drive/MyDrive/Nodular HV3 C y C/modulos_HV3_200x_0{i}.tif')
  #print(file)
  files.append(file)

for i in range(10,121):
  file=(f'/content/drive/MyDrive/Nodular HV3 C y C/modulos_HV3_200x_{i}.tif')
  #print(file)
  files.append(file)

for each in files:
  img = cv2.imread(each)  #Try houses.jpg or neurons.jpg
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  arr = np.array(img, dtype=np.uint8) # Convertir la imagen a un arreglo de NumPy
  imagenes.append(arr)

print(imagenes[0].shape)#(2.22:3.27)
#(512, 768)#56.70

new=[]
#ver una por una y cortar el extremo para ver si funcionA
for img in imagenes:
    nuevo=img[:-56]
    nuevo=nuevo[:, 70:]
    new.append(nuevo)
new=np.array(new)
print(new.shape)


patches = patchify(new[0], (2,2), step=2)
print(patches.shape)

#mask= np.array(mask, dtype=np.uint8)

#This will split the image into small images of shape [3,3]
patchess = []
i=0
for img in new:
  i+=1
  patch = patchify(img, (256, 256), step=256)  #Step=256 for 256 patches means no overlap
  #print(patch.shape)
  patchess.append(patch)

#------------------
plt.figure(figsize=(8, 8))
plt.subplot(221)
plt.title('Cropped')
plt.imshow(np.reshape(patchess[0][1][1], (256, 256)))
#plt.imshow(imagenes[0])

predicted_patches = []
predicted_patches_array = []

k=0
for patches in patchess:
  k+=1
  for i in range(patches.shape[0]):
      for j in range(patches.shape[1]):
          print(i,j)

          single_patch = patches[i,j,:,:]
          single_patch_norm = np.expand_dims(normalize(single_patch, axis=1),2)
          single_patch_input=np.expand_dims(single_patch_norm, 0)

  #Prediction here
          single_patch_prediction = (model.predict(single_patch_input))#.astype(np.uint8)
          predicted_img=np.argmax(single_patch_prediction, axis=3)[0,:,:]#.astype(np.uint8)
          print(predicted_img[0])

          plt.figure(figsize=(5, 5))
          plt.subplot(221)
          plt.title('Original Cropped')
          plt.imshow(single_patch, cmap='gray')
          plt.subplot(222)
          plt.title('Prediction Cropped')
          plt.imshow(predicted_img)
          plt.show()

          predicted_patches.append(predicted_img)

  x = np.array(predicted_patches)
  predicted_patches.clear()
  predicted_patches_array.append(x)
  x=0#np.array([])#deleting all elements

print(predicted_patches_array[0].shape)
print(patches.shape)
print(imagenes[0].shape)

#------------------
plt.figure(figsize=(8, 8))
plt.subplot(221)
plt.title('Cropped')
plt.imshow(predicted_patches_array[50][0], cmap='gray')

reconstructed_image_array=[]

for pred in predicted_patches_array:
  predicted_patches_reshaped = np.reshape(pred, (patches.shape[0], patches.shape[1], 256,256) )
  reconstructed_image = unpatchify(predicted_patches_reshaped, imagenes[0].shape)
  reconstructed_image_array.append(reconstructed_image)
  #plt.imshow(reconstructed_image, cmap='gray')
  #plt.show()
#plt.imsave('data/results/segm.jpg', reconstructed_image, cmap='gray')

#plt.hist(reconstructed_image.flatten())  #Threshold everything above 0

# final_prediction = (reconstructed_image > 0.01).astype(np.uint8)
# plt.imshow(final_prediction)

plt.figure(figsize=(8, 8))
plt.subplot(221)
plt.title('Large Image')
plt.imshow(imagenes[32], cmap='gray')
plt.subplot(222)
plt.title('Prediction of large Image')
plt.imshow(reconstructed_image_array[32], cmap='gray')
plt.show()