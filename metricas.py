# -*- coding: utf-8 -*-
"""Metricas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qrg8OCfrZbdTTpvYSFZEwsawc9QaED-5

## import all libraries & Load Images
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
import os
import cv2
import numpy as np
from PIL import Image
import glob
# %pip install patchify
from patchify import patchify, unpatchify

from skimage import img_as_ubyte
from matplotlib import pyplot as plt
from PIL import Image
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler, StandardScaler
#import tifffile as tfl
#import matplotlib.image as mpimg

# %pip install keras_unet_collection
from keras_unet_collection import models, losses

import torch
import torchvision
print("PyTorch version:", torch.__version__)
print("Torchvision version:", torchvision.__version__)
print("CUDA is available:", torch.cuda.is_available())
import sys
!{sys.executable} -m pip install opencv-python matplotlib
!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything-2.git'

!mkdir -p images
!wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/cars.jpg

!mkdir -p ../checkpoints/
!wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt

import os
# if using Apple MPS, fall back to CPU for unsupported ops
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
import numpy as np
import torch
import matplotlib.pyplot as plt
from PIL import Image

# select the device for computation
if torch.cuda.is_available():
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")
print(f"using device: {device}")

if device.type == "cuda":
    # use bfloat16 for the entire notebook
    torch.autocast("cuda", dtype=torch.bfloat16).__enter__()
    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)
    if torch.cuda.get_device_properties(0).major >= 8:
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
elif device.type == "mps":
    print(
        "\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might "
        "give numerically different outputs and sometimes degraded performance on MPS. "
        "See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion."
    )

from sklearn.model_selection import KFold
from sklearn.metrics import jaccard_score, precision_score, f1_score
def change_white_black(image_array):
    # Encontrar los píxeles blancos y cambiarlos a negros
    white_pixels = (image_array == 255)
    black_pixels = (image_array == 0)
    image_array[white_pixels] = 0
    image_array[black_pixels] = 255

def change_0_1 (image_array):
    # Encontrar los píxeles blancos y cambiarlos a negros
    white_pixels = (image_array == 255)
    black_pixels = (image_array == 0)
    image_array[white_pixels] = 1
    image_array[black_pixels] = 0

def pixel_counting (image_array, cluster_centers):
  dic={}
  n=-1
  for _ in cluster_centers:
    n+=1
    dic[n]=0
  # Iterate through each cluster
  for x in range (image_array.shape[0]):
    for y in range (image_array.shape[1]):
      pixel_value = image_array[x][y]
      #print(pixel_value)
      nn=-1
      for each in cluster_centers:
        nn+=1
      # Check if the pixel value matches any of the cluster centers
        if np.all(pixel_value == each):
          dic[nn] += 1
  return dic

def get_clave(diccionario, max_value):
  for clave, valor in diccionario.items():
      # Verifica si el valor coincide con el valor buscado
      if valor == max_value:
          # Si coincide, agrega la clave a la lista de claves coincidentes
          claves_coincidente=clave
  return claves_coincidente

import tensorflow as tf
from tensorflow.keras.metrics import MeanIoU
from skimage.metrics import mean_squared_error

def compute_metrics(y_true, y_pred):
    # Flatten the arrays to compute metrics
    y_true_flat = y_true.flatten()
    y_pred_flat = y_pred.flatten()

    # IoU (Jaccard Index)
    iou = jaccard_score(y_true_flat, y_pred_flat, average='weighted')

    # Dice Coefficient (F1 Score)
    dice = f1_score(y_true_flat, y_pred_flat, average='weighted')

    # Precision
    precision = precision_score(y_true_flat, y_pred_flat, average='weighted')

    return iou, dice, precision

def k_fold_cross_validation(X, y, k=5):
    kf = KFold(n_splits=k, shuffle=True, random_state=42)

    iou_scores = []
    dice_scores = []
    precision_scores = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # Dummy example: here you would train your model on X_train, y_train and predict on X_test
        # For demonstration, we'll assume y_pred is just y_test to show how metrics would work.
        #y_pred = y_test  # Replace with model predictions

        iou, dice, precision = compute_metrics(y_test, X_test)

        iou_scores.append(iou)
        dice_scores.append(dice)
        precision_scores.append(precision)

    return np.mean(iou_scores), np.mean(dice_scores), np.mean(precision_scores)


import tensorflow as tf
from tensorflow.keras.metrics import MeanIoU
from skimage.metrics import mean_squared_error

from skimage import io, util
# Leer todas las imágenes JPG en un directorio específico
imagenes = []
files=[]
for i in range(1,10):
  file=(f'/content/drive/MyDrive/Nodular HV3 C y C/modulos_HV3_200x_0{i}.tif')
  #print(file)
  files.append(file)

for i in range(10,121):
  file=(f'/content/drive/MyDrive/Nodular HV3 C y C/modulos_HV3_200x_{i}.tif')
  #print(file)
  files.append(file)

for each in files:
  img = cv2.imread(each)  #Try houses.jpg or neurons.jpg
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  arr = np.array(img, dtype=np.uint8) # Convertir la imagen a un arreglo de NumPy
  imagenes.append(arr)

mask1 = io.imread("/content/drive/MyDrive/Colab Notebooks/Nodular/hierro_alineado.tiff")
#mask= np.array(mask, dtype=np.uint8)

# Leer todas las imágenes JPG en un directorio específico

for filename in sorted(glob.iglob('/content/drive/MyDrive/Hierro_gris/*.jpg')):
  img = cv2.imread(filename)  #Try houses.jpg or neurons.jpg
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  arr = np.array(img, dtype=np.uint8) # Convertir la imagen a un arreglo de NumPy
  resized_image = cv2.resize(arr, (838, 568))
  imagenes.append(resized_image)
mask2 = io.imread("/content/drive/MyDrive/Mask_Hierro_gris_stack_8bits.tif")
resized_images = []
for i in range(mask2.shape[0]):  # Recorrer cada "imagen"
    img = mask2[i, :, :]  # Seleccionar una "imagen"
    resized_img = cv2.resize(img, (838, 568))
    change_white_black(resized_img)
    resized_images.append(resized_img)
resized_images
mask2 = np.stack(resized_images, axis=0)
#mask= np.array(mask, dtype=np.uint8)

mask1 = np.array(mask1, dtype=np.uint8)
print(mask1.shape)
mask2 = np.array(mask2, dtype=np.uint8)
#mask2 = cv2.resize(mask2, (568, 838))
print(mask2.shape)
mask=np.concatenate((mask1, mask2), axis=0)

"""# CLUSTERS"""

from sklearn.cluster import KMeans
imagenes_reshaped = []
for img in imagenes:
  x=img.reshape(-1,3)
  imagenes_reshaped.append(x)
print(imagenes_reshaped[0].shape[0])

imagen1=imagenes_reshaped[0]
kmeans=KMeans(n_clusters=3, n_init=10)
#kmeans.fit(imagenes_reshaped[0])

#segmented_img= kmeans.cluster_centers_[kmeans.labels_]
#segmented_img_=segmented_img.reshape(imagenes[0].shape)
#print(kmeans.labels_)

kmeans.fit(imagenes_reshaped[0])
  segmented_img= kmeans.cluster_centers_[kmeans.labels_]
  print(kmeans.cluster_centers_)
  print("=======================================================")
  print(segmented_img)
  #segmented_img_=segmented_img.reshape(imagenes[n].shape)

n=0
clustered_images=[]
error_cluster=[]
error={}#dictionary error[number of image]=[mean squared error value, IOU value, otras metricas que deberia ponerle]

#flood fill per cluster---weak
#pixel counting per cluster--nice
#color ---too weak
#bounding box de cada cluster


#imagen binary*----- IoU, median filter(if it doesnt work morphology)---eliminar los puntos chiquitos(salt and pepper noise)

for each in imagenes_reshaped:
  kmeans.fit(each)
  segmented_img= kmeans.cluster_centers_[kmeans.labels_]

  segmented_img_=segmented_img.reshape(imagenes[n].shape)
  img=np.array(segmented_img_, dtype=np.uint8)
  clustered_images.append(img)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  min= np.min(img)
  #_, img = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY)
  img = np.where((img > min), 255, 0)
  #contornos, jerarquia = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  mascara=mask[n]


  plt.figure(figsize=(12, 12))
  plt.subplot(131)
  plt.title(f'Original {n}')
  plt.imshow(imagenes[n], cmap='gray')
  plt.subplot(132)
  plt.imshow (img, cmap="gray")
  plt.title('cluster')
  plt.subplot(133)
  plt.imshow (mascara, cmap="gray")
  plt.title(' G Truth Mask')
  plt.show()

  metricas=compute_metrics(mascara,img)#y_true, y_pred
  error_cluster.append(metricas[0])
  print(metricas[0])
  #change_white_black(mascara)
  print(mascara[0][0])
  print(img[0][0])

##-----IMPORTANTE----Aqui cambio el formato, si quieres recuperar debes correr
#                     todo el codigo desde cargar las imagenes u optimizarlo


  #change_0_1 (img)
  #change_0_1 (mascara)
  mse_value = np.mean((mascara - img ) ** 2)
  # Definir la métrica MeanIoU
  #mean_iou = MeanIoU(num_classes=2)
  # Actualizar la métrica con los datos de ejemplo
  #mean_iou.update_state(img, mascara)
  # Calcular el Mean IoU
  #Iou_VALUE = mean_iou.result().numpy()




  #error.append(mse_value,Iou_VALUE)
# Print the MSE
  print("Mean Squared Error (MSE):", mse_value)
  error[n] = [mse_value]
  n+=1

# Crear una lista de listas que contenga los valores importantes para cada clave
value1_array =  error_cluster[:120]
value2_array = error_cluster[120:]
print(len(value2_array))


plt.subplots(1, 2, figsize=(10, 5))
# Crear dos subplots
plt.subplot(1, 2, 1)
plt.hist(value1_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (NODULAR)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.hist(value2_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (GREY)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

# Ajustar el espaciado entre subplots
plt.tight_layout()

# Mostrar la figura con los subplots
plt.show()

plt.subplots(1, 2, figsize=(10, 5))
# Crear dos subplots
plt.subplot(1, 2, 1)
plt.boxplot(value1_array)
plt.title('Distribución del Mean Squared Error (MSE)')
plt.xlabel('Distancia entre el valor verdadero y la prediccion')
plt.ylabel('Mean Squared Error (MSE)')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.boxplot(value2_array)
plt.title('Distribución del IoU (Jaccard)')
plt.xlabel('IoU=0=superposición incorrecta   IoU=1=superposición perfecta')
plt.ylabel('IoU')
plt.grid(True)

# Ajustar el espaciado entre subplots
plt.tight_layout()

# Mostrar la figura con los subplots
plt.show()

"""# Watershed"""

#taken from https://www.youtube.com/watch?v=AsTvGxuiqKs

from scipy import ndimage
from skimage import measure, color, io
error_watershed=[]
for n in range(len(imagenes)):
  imagen=imagenes[n]
  pixels_to_um = 0.454 # 1 pixel = 454 nm


  #Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255
  img = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)

  # Morphological operations to remove small noise - opening
  #To remove holes we can use closing
  kernel = np.ones((3,3),np.uint8)
  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN, kernel, iterations = 2)

  # let us start by identifying sure background area
  sure_bg = cv2.dilate(opening,kernel,iterations=10)

  # Finding sure foreground area using distance transform and thresholding
  dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2,3)

  #Let us threshold the dist transform by starting at 1/2 its max value.
  print(dist_transform.max()) #gives about 21.9
  ret2, sure_fg = cv2.threshold(dist_transform,0.01*dist_transform.max(),255,0)

  # Unknown ambiguous region is nothing but bkground - foreground
  sure_fg = np.uint8(sure_fg)
  unknown = cv2.subtract(sure_bg, sure_fg)

  ret3, markers = cv2.connectedComponents(sure_fg)

  markers = markers+10

  markers[unknown==255] = 0
  #plt.imshow(markers, cmap='jet')

  #Now we are ready for watershed filling.
  markers = cv2.watershed(imagen,markers)

  imagen[markers == -1] = [255,255,255]
  min= np.min(markers)
  _, img = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY)
  markers = np.where((markers > min), 255, 0)
  mascara=mask[n]
  img2 = color.label2rgb(markers, bg_label=0)
  metricas=compute_metrics(mascara,markers)#y_true, y_pred
  error_watershed.append(metricas[0])
  print(metricas[0])

  plt.figure(figsize=(12, 12))
  plt.subplot(131)
  plt.title(f'Original {n}')
  plt.imshow(imagen, cmap='gray')
  plt.subplot(132)
  plt.imshow (markers, cmap="gray")
  plt.title(''"Dist transform"'')
  plt.subplot(133)
  plt.imshow (mascara, cmap="gray")
  plt.title(' G Truth Mask')
  plt.show()

plt.figure(figsize=(12, 12))
plt.subplot(131)
plt.title(f'Original {n}')
plt.imshow(imagenes[n], cmap='gray')
plt.subplot(132)
plt.imshow (dist_transform, cmap="gray")
plt.title(''"Dist transform"'')
plt.subplot(133)
plt.imshow (mascara, cmap="gray")
plt.title(' G Truth Mask')
plt.show()

# Crear una lista de listas que contenga los valores importantes para cada clave
error_watershed_value1_array =  error_watershed[:120]
error_watershed_value2_array = error_watershed[120:]
print(len(value2_array))


plt.subplots(1, 2, figsize=(10, 5))
# Crear dos subplots
plt.subplot(1, 2, 1)
plt.hist(error_watershed_value1_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (NODULAR)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.hist(error_watershed_value2_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (GREY)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

# Ajustar el espaciado entre subplots
plt.tight_layout()

# Mostrar la figura con los subplots
plt.show()

"""##SAM 2"""

def show_anns_color(anns, borders=True):
    if len(anns) == 0:
        return
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
    img[:, :, 3] = 0
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([np.random.random(3), [0.5]])
        img[m] = color_mask
        if borders:
            import cv2
            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            # Try to smooth contours
            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]
            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)

    ax.imshow(img)
    return img

def show_anns(anns, borders=True):
    if len(anns) == 0:
        return
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
    img[:, :, 3] = 0
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([[255,255,255], [0.5]])
        img[m] = color_mask
    ax.imshow(img)
    return img

from sam2.build_sam import build_sam2
from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator
error_SAM=[]
sam2_checkpoint = "../checkpoints/sam2_hiera_large.pt"
model_cfg = "sam2_hiera_l.yaml"

sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)
"""
mask_generator = SAM2AutomaticMaskGenerator(sam2)
masks = mask_generator.generate(imagenes[0])
"""
mask_generator_2 = SAM2AutomaticMaskGenerator(
    model=sam2,
    points_per_side=64,
    points_per_batch=128,
    pred_iou_thresh=0.7,
    stability_score_thresh=0.97,
    stability_score_offset=0.5,
    crop_n_layers=1,
    box_nms_thresh=0.7,
    crop_n_points_downscale_factor=2,
    min_mask_region_area=25.0,
    use_m2m=True,
)

for n in range(len(imagenes)):
  imagen=imagenes[n]
  mascara=mask[n]
  black=np.ones_like(mascara)#*255
  masks2 = mask_generator_2.generate(imagen)

  plt.figure(figsize=(12, 12))
  plt.subplot(131)
  plt.title(f'Original {n}')
  plt.imshow(imagen, cmap='gray')
  plt.subplot(132)
  plt.imshow (black, cmap="gray")
  pred=show_anns(masks2)
  to_show_image=show_anns_color(masks2)
  arr_2d=pred[:, :, 0]*255
  image_uint8 = arr_2d.astype(np.uint8)
  arr_invertido = 255 - image_uint8  # Invertir colores
  plt.title(''"SAM"'')

  #image_rgb = pred[:, :, :3]

# Convertir a una imagen en escala de grises (opcional)
  #image_uint8 = image_rgb.astype(np.uint8)
# Aplicar la umbralización para mantener solo los píxeles blancos
  #_, binary_image = cv2.threshold(image_rgb, 250, 255, cv2.THRESH_BINARY_INV)
  #pred = cv2.cvtColor(binary_image, cv2.COLOR_BGR2GRAY)

  plt.subplot(133)
  plt.imshow (mascara, cmap="gray")
  plt.title(' G Truth Mask')
  plt.show()
  metricas=compute_metrics(mascara,image_uint8)#y_true, y_pred
  print(metricas)
  error_SAM.append(metricas[0])

# Crear una lista de listas que contenga los valores importantes para cada clave
error_SAM_value1_array =  error_SAM[:120]
error_SAM_value2_array = error_SAM[120:]
print(len(value2_array))


plt.subplots(1, 2, figsize=(10, 5))
# Crear dos subplots
plt.subplot(1, 2, 1)
plt.hist(error_SAM_value1_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (NODULAR)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.hist(error_SAM_value2_array, bins=10, color='skyblue', edgecolor='black')
plt.title('Distribución del IoU (GREY)')
plt.xlabel('Valores')
plt.ylabel('IoU (Jaccard)')
plt.grid(True)

# Ajustar el espaciado entre subplots
plt.tight_layout()

# Mostrar la figura con los subplots
plt.show()

"""las tres en una sola grafica

"""

# Superponer las distribuciones de ambos errores en un solo gráfico
plt.figure(figsize=(8, 6))

# Distribución del error_cluster
plt.hist(error_cluster, bins=10, color='skyblue', edgecolor='black', alpha=0.6, label='Accuracy_cluster')

# Distribución del error_watershed
plt.hist(error_watershed, bins=10, color='lightcoral', edgecolor='black', alpha=0.6, label='Accuracy_watershed')

# Distribución del error_SAM
plt.hist(error_SAM, bins=10, color='lightgreen', edgecolor='black', alpha=0.6, label='Accuracy_SAM')

# Añadir títulos y leyendas
plt.title('Comparación de Errores: error_cluster vs error_watershed')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend(loc='upper right')
plt.grid(True)

# Mostrar la gráfica
plt.show()